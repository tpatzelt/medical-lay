{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T06:51:53.731835371Z",
     "start_time": "2023-07-20T06:51:53.689035538Z"
    },
    "id": "JIMIADfjBqz2"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tim/PycharmProjects/medical-lay/src\")\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.spatial.distance import cdist\n",
    "import json\n",
    "from config import  TLCPaths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T06:51:53.736939001Z",
     "start_time": "2023-07-20T06:51:53.735106758Z"
    },
    "id": "SdzdI_ZG-0l9"
   },
   "outputs": [],
   "source": [
    "## functions\n",
    "def get_batched_closest_index_idx(emb, index_embeddings):\n",
    "  dist = cdist(emb, index_embeddings, metric=\"cosine\")\n",
    "  return np.argsort(dist,axis=-1)[:,:64]\n",
    "\n",
    "def get_batched_closest_cuis(emb, index_embedding, index_cuis):\n",
    "  closest_cui_idx = get_batched_closest_index_idx(emb, index_embedding)\n",
    "  return np.array([[index_cuis[cui_idx] for cui_idx in single_closest_cui_idx] for single_closest_cui_idx in closest_cui_idx])\n",
    "\n",
    "def top_k_acc(y_true, y_pred, k=1):\n",
    "  y_pred = y_pred[:,:k]\n",
    "  correct_preds = [true in pred for true,pred in zip(y_true,y_pred)]\n",
    "  return np.mean(correct_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T06:52:12.077413003Z",
     "start_time": "2023-07-20T06:51:53.742437052Z"
    },
    "id": "v2A2fiiE-QKZ"
   },
   "outputs": [],
   "source": [
    "# mention in sentence embedding\n",
    "sentence_embedding_file = Path(TLCPaths.project_data_path /\"embeddings/SAPBERT_XMLR_mention_with_sentence_embeddings.npy\")\n",
    "mention_token_file = Path(TLCPaths.project_data_path / \"embeddings/SAPBERT_XMLR_mention_with_sentence_offsets.npy\")\n",
    "sentence_hidden_states = np.load(sentence_embedding_file)\n",
    "mention_token_indices = np.load(mention_token_file, allow_pickle=True)\n",
    "\n",
    "# only mention embedding\n",
    "mention_embedding_file = Path(TLCPaths.project_data_path / \"embeddings/SAPBERT_XMLR_large_mention_embedding.npy\")\n",
    "mention_hidden_states = np.load(mention_embedding_file)\n",
    "\n",
    "# index embeddings\n",
    "cls_index_file = Path(TLCPaths.project_data_path / \"embeddings/SAPBERT_XMLR_large_umls_search_index_cls_token\")\n",
    "mean_all_index_file = Path(TLCPaths.project_data_path / \"embeddings/SAPBERT_XMLR_large_umls_search_index_mean_token\")\n",
    "mean_no_cls_index_file = Path(TLCPaths.project_data_path / \"embeddings/SAPBERT_XMLR_large_umls_search_index_mean_no_cls_token\")\n",
    "cls_token_index = np.concatenate([np.load(str(cls_index_file) + f\"_{file_idx}.npy\") for file_idx in range(5)])\n",
    "mean_all_token_index = np.concatenate([np.load(str(mean_all_index_file) + f\"_{file_idx}.npy\") for file_idx in range(5)])\n",
    "mean_no_cls_token_index = np.concatenate([np.load(str(mean_no_cls_index_file) + f\"_{file_idx}.npy\") for file_idx in range(5)])\n",
    "\n",
    "concept_names, concept_cuis = [], []\n",
    "with open(TLCPaths.project_data_path / \"german_umls_names_and_cuis.csv\", newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    for row in reader:\n",
    "      assert len(row)== 2\n",
    "      concept_cuis.append(row[0])\n",
    "      concept_names.append(row[1].strip())\n",
    "\n",
    "\n",
    "with open(TLCPaths.project_data_path / \"TLC_UMLS.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    X = [entry[\"mention\"] for entry in data]\n",
    "    Y = [entry[\"cui\"] for entry in data]\n",
    "    X_sent = [entry[\"mention_sentence\"].strip() for entry in data]\n",
    "    Y_sent = Y\n",
    "    mention_offsets = [entry[\"mention_sentence_spans\"] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bfDy_PHT-QM1"
   },
   "outputs": [],
   "source": [
    "sentence_cls_token_rep = sentence_hidden_states[:,0,:]\n",
    "\n",
    "mention_token_reps = []\n",
    "for i, token_indices in enumerate(mention_token_indices):\n",
    "  if not token_indices:\n",
    "    token_indices = range(150) # 5 token indices are empty ?!\n",
    "  single_mention_token_reps = []\n",
    "  for token_index in token_indices:\n",
    "    single_mention_token_reps.append(sentence_hidden_states[i,token_index,:])\n",
    "  mention_token_reps.append(single_mention_token_reps)\n",
    "\n",
    "sentence_mention_token_rep = np.array([np.mean(emb,axis=0) for emb in mention_token_reps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yPhSqE1C0Jw9"
   },
   "outputs": [],
   "source": [
    "mention_cls_token_rep = mention_hidden_states[:,0,:]\n",
    "mention_mean_token_rep = mention_hidden_states.mean(axis=1)\n",
    "mention_no_cls_token_rep = mention_hidden_states[:,1:,:].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SDG31ChL7FGZ"
   },
   "outputs": [],
   "source": [
    "k_values = [1,2,4,8,16,32,64]\n",
    "\n",
    "result_accuracies = {}\n",
    "predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1g6Uze37JEhx"
   },
   "source": [
    "# get predictions\n",
    "1. mention with and without sentence context on cls token index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxvgU6YC7gkl",
    "outputId": "88145fd7-6684-481d-eeb5-2bea78a711de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mention cls token on cls token index\n"
     ]
    }
   ],
   "source": [
    "print(\"mention cls token on cls token index\")\n",
    "name = \"SAPBERT_cls_token_on_cls_index\"\n",
    "Y_pred = get_batched_closest_cuis(mention_cls_token_rep, cls_token_index, index_cuis=concept_cuis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coAyX7aS9pMZ"
   },
   "outputs": [],
   "source": [
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-CuBBd_CUi8"
   },
   "outputs": [],
   "source": [
    "print(\"mention mean of all token on cls token index\")\n",
    "name = \"SAPBERT_mean_token_on_cls_index\"\n",
    "Y_pred = get_batched_closest_cuis(mention_mean_token_rep, cls_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqOxOVCJCges"
   },
   "outputs": [],
   "source": [
    "print(\"mention mean of all except cls token on cls token index\")\n",
    "name = \"SAPBERT_mean_no_cls_token_on_cls_index\"\n",
    "Y_pred = get_batched_closest_cuis(mention_no_cls_token_rep, cls_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lzXFel1GI38"
   },
   "outputs": [],
   "source": [
    "print(\"sentence with mention cls token on cls token index\")\n",
    "name = \"SAPBERT_sent_cls_token_on_cls_index\"\n",
    "Y_pred = get_batched_closest_cuis(sentence_cls_token_rep, cls_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cARmAnTjGJro"
   },
   "outputs": [],
   "source": [
    "print(\"mean mention in sentence token on cls token index\")\n",
    "name = \"SAPBERT_sent_mean_token_on_cls_index\"\n",
    "Y_pred = get_batched_closest_cuis(sentence_mention_token_rep, cls_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cls_token_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-nPdHLhtubM"
   },
   "source": [
    "2. mention with and without sentence context on mean token index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfpZAhVBGWC-"
   },
   "outputs": [],
   "source": [
    "print(\"mention cls token on mean token index\")\n",
    "name = \"SAPBERT_cls_token_on_mean_index\"\n",
    "Y_pred = get_batched_closest_cuis(mention_cls_token_rep, mean_all_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred\n",
    "\n",
    "print(\"mention mean of all token on mean token index\")\n",
    "name = \"SAPBERT_mean_all_token_on_mean_index\"\n",
    "Y_pred = get_batched_closest_cuis(mention_mean_token_rep, mean_all_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred\n",
    "\n",
    "print(\"mention mean of all except cls token on mean token index\")\n",
    "name = \"SAPBERT_mean_no_cls_token_on_mean_index\"\n",
    "Y_pred = get_batched_closest_cuis(mention_no_cls_token_rep, mean_all_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred\n",
    "\n",
    "print(\"sentence with mention cls token on mean token index\")\n",
    "name = \"SAPBERT_sent_cls_token_on_mean_index\"\n",
    "Y_pred = get_batched_closest_cuis(sentence_cls_token_rep, mean_all_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred\n",
    "\n",
    "print(\"mean mention in sentence token on mean token index\")\n",
    "name = \"SAPBERT_sent_mean_mention_token_on_mean_index\"\n",
    "Y_pred = get_batched_closest_cuis(sentence_mention_token_rep, mean_all_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mean_all_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XzKuqKSV9S0t"
   },
   "outputs": [],
   "source": [
    "print(\"mention cls token on mean no cls token index\")\n",
    "name = \"SAPBERT_cls_token_on_mean_no_cls_index\"\n",
    "Y_pred = get_batched_closest_cuis(mention_cls_token_rep, mean_no_cls_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred\n",
    "\n",
    "print(\"mention mean of all token on mean _no_cls token index\")\n",
    "name = \"SAPBERT_mean_all_token_on_mean_no_cls_index\"\n",
    "Y_pred = get_batched_closest_cuis(mention_mean_token_rep, mean_no_cls_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred\n",
    "\n",
    "print(\"mention mean of all except cls token on mean _no_cls token index\")\n",
    "name = \"SAPBERT_mean_no_cls_token_on_mean_no_cls_index\"\n",
    "Y_pred = get_batched_closest_cuis(mention_no_cls_token_rep, mean_no_cls_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred\n",
    "\n",
    "print(\"sentence with mention cls token on mean _no_cls token index\")\n",
    "name = \"SAPBERT_sent_cls_token_on_mean_no_cls_index\"\n",
    "Y_pred = get_batched_closest_cuis(sentence_cls_token_rep, mean_no_cls_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred\n",
    "\n",
    "print(\"mean mention in sentence token on mean _no_cls token index\")\n",
    "name = \"SAPBERT_sent_mean_mention_token_on_mean_no_cls_index\"\n",
    "Y_pred = get_batched_closest_cuis(sentence_mention_token_rep, mean_no_cls_token_index, index_cuis=concept_cuis)\n",
    "accs = [round(top_k_acc(Y,Y_pred, k=i),3) for i in k_values]\n",
    "_ = [print(f\"Acc@{i}: {acc}\") for i, acc in zip(k_values,accs)]\n",
    "result_accuracies[name] = accs\n",
    "predictions[name] = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9GlpVt0IOaU"
   },
   "outputs": [],
   "source": [
    "accuracies_file = Path(TLCPaths.project_data_path / \"sapbert_accuracies.json\")\n",
    "predictions_file = Path(TLCPaths.project_data_path / \"sapbert_predictions.json\")\n",
    "import json\n",
    "with open(accuracies_file, \"w\") as f:\n",
    "  json.dump(result_accuracies, f)\n",
    "with open(predictions_file, \"w\") as f:\n",
    "  json.dump(predictions, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rp7naVtOI6bk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
